{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/collection/ka2khan/thesis/Cond_Text_Gen\n",
      "Reading file: data/DailyDialog/processed/train_tuples.tsv\n",
      "Reading file: data/DailyDialog/processed/valid_tuples.tsv\n",
      "Reading file: data/DailyDialog/processed/test_tuples.tsv\n",
      "329\n",
      "333\n",
      "9 -> 4346\n",
      "10 -> 4227\n",
      "8 -> 4177\n",
      "11 -> 4167\n",
      "12 -> 3969\n",
      "7 -> 3869\n",
      "13 -> 3635\n",
      "14 -> 3396\n",
      "6 -> 3187\n",
      "15 -> 3165\n",
      "16 -> 3011\n",
      "17 -> 2734\n",
      "18 -> 2551\n",
      "19 -> 2402\n",
      "20 -> 2245\n",
      "4 -> 1995\n",
      "21 -> 1993\n",
      "22 -> 1905\n",
      "23 -> 1723\n",
      "24 -> 1604\n",
      "5 -> 1603\n",
      "25 -> 1516\n",
      "26 -> 1329\n",
      "3 -> 1253\n",
      "27 -> 1176\n",
      "28 -> 1077\n",
      "29 -> 961\n",
      "30 -> 862\n",
      "31 -> 829\n",
      "32 -> 696\n",
      "33 -> 684\n",
      "34 -> 648\n",
      "35 -> 587\n",
      "36 -> 530\n",
      "38 -> 483\n",
      "37 -> 454\n",
      "39 -> 432\n",
      "40 -> 360\n",
      "41 -> 331\n",
      "43 -> 321\n",
      "42 -> 304\n",
      "44 -> 294\n",
      "45 -> 257\n",
      "46 -> 246\n",
      "48 -> 240\n",
      "47 -> 229\n",
      "49 -> 195\n",
      "50 -> 184\n",
      "52 -> 169\n",
      "51 -> 168\n",
      "53 -> 153\n",
      "54 -> 150\n",
      "55 -> 113\n",
      "56 -> 106\n",
      "59 -> 105\n",
      "57 -> 90\n",
      "58 -> 88\n",
      "60 -> 85\n",
      "62 -> 79\n",
      "63 -> 77\n",
      "61 -> 73\n",
      "65 -> 61\n",
      "67 -> 54\n",
      "66 -> 53\n",
      "68 -> 47\n",
      "73 -> 41\n",
      "64 -> 41\n",
      "70 -> 41\n",
      "71 -> 39\n",
      "69 -> 36\n",
      "75 -> 32\n",
      "72 -> 32\n",
      "74 -> 30\n",
      "80 -> 24\n",
      "77 -> 24\n",
      "81 -> 22\n",
      "76 -> 21\n",
      "78 -> 21\n",
      "2 -> 20\n",
      "82 -> 18\n",
      "79 -> 16\n",
      "85 -> 16\n",
      "88 -> 14\n",
      "94 -> 14\n",
      "84 -> 14\n",
      "83 -> 14\n",
      "89 -> 14\n",
      "90 -> 13\n",
      "95 -> 12\n",
      "97 -> 11\n",
      "86 -> 11\n",
      "87 -> 10\n",
      "98 -> 10\n",
      "99 -> 9\n",
      "92 -> 8\n",
      "96 -> 8\n",
      "91 -> 8\n",
      "101 -> 8\n",
      "102 -> 7\n",
      "112 -> 6\n",
      "118 -> 6\n",
      "103 -> 6\n",
      "1 -> 6\n",
      "107 -> 6\n",
      "106 -> 5\n",
      "100 -> 5\n",
      "122 -> 4\n",
      "109 -> 4\n",
      "125 -> 4\n",
      "143 -> 4\n",
      "110 -> 4\n",
      "108 -> 3\n",
      "105 -> 3\n",
      "104 -> 3\n",
      "117 -> 3\n",
      "121 -> 3\n",
      "128 -> 3\n",
      "93 -> 3\n",
      "113 -> 2\n",
      "111 -> 2\n",
      "164 -> 2\n",
      "132 -> 2\n",
      "163 -> 2\n",
      "119 -> 2\n",
      "324 -> 2\n",
      "136 -> 2\n",
      "130 -> 2\n",
      "127 -> 2\n",
      "129 -> 2\n",
      "126 -> 2\n",
      "156 -> 2\n",
      "191 -> 1\n",
      "179 -> 1\n",
      "162 -> 1\n",
      "208 -> 1\n",
      "116 -> 1\n",
      "192 -> 1\n",
      "131 -> 1\n",
      "123 -> 1\n",
      "138 -> 1\n",
      "153 -> 1\n",
      "216 -> 1\n",
      "141 -> 1\n",
      "115 -> 1\n",
      "173 -> 1\n",
      "114 -> 1\n",
      "139 -> 1\n",
      "180 -> 1\n",
      "211 -> 1\n",
      "270 -> 1\n",
      "333 -> 1\n",
      "135 -> 1\n",
      "151 -> 1\n",
      "133 -> 1\n",
      "197 -> 1\n",
      "267 -> 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import T5Tokenizer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "dataset =  {\n",
    "                'parts': ['train', 'valid', 'test'],\n",
    "                'sentences': {'train': 'processed/train_sentences.tsv', 'valid': 'processed/valid_sentences.tsv', 'test': 'processed/test_sentences.tsv'},\n",
    "                'tuples': {'train': 'processed/train_tuples.tsv', 'valid': 'processed/valid_tuples.tsv', 'test': 'processed/test_tuples.tsv'},\n",
    "}\n",
    "\n",
    "os.chdir('/collection/ka2khan/thesis/Cond_Text_Gen')\n",
    "print(os.getcwd())\n",
    "\n",
    "data_path = 'data/DailyDialog'\n",
    "\n",
    "contexts = {}\n",
    "curr_sents = {}\n",
    "next_sents = {}\n",
    "for part in dataset['parts']:\n",
    "    contexts[part] = []\n",
    "    curr_sents[part] = []\n",
    "    next_sents[part] = []\n",
    "\n",
    "    file_path = os.path.join(data_path, dataset['tuples'][part])\n",
    "    print(f\"Reading file: {file_path}\")\n",
    "    with open(file_path) as f_obj:\n",
    "        reader = csv.reader(f_obj, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            assert len(row) == 3, f'Error! row does not contain exactly three items! Count: {len(row)}'\n",
    "\n",
    "            contexts[part].append(row[0])\n",
    "            curr_sents[part].append(row[1])\n",
    "            next_sents[part].append(row[2])\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "input_lengths = []\n",
    "output_lengths = []\n",
    "for part in dataset['parts']:\n",
    "    for index, sent in enumerate(curr_sents[part]):\n",
    "        input_seq = 'generate response query: ' + sent + ' </s>'\n",
    "        input_lengths.append(len(tokenizer.encode(input_seq)))\n",
    "        output_lengths.append(len(tokenizer.encode(next_sents[part][index])))\n",
    "        \n",
    "print(np.max(input_lengths))\n",
    "print(np.max(output_lengths))\n",
    "\n",
    "counter = Counter(output_lengths)\n",
    "for item in counter.most_common():\n",
    "    print(f'{item[0]} -> {item[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
